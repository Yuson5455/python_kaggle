{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "news=fetch_20newsgroups(subset='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(news.data,news.target,test_size=0.25,random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用CountVectorizer并且不去掉停用词的条件下，对文本特征进行量化的naive bayes classifier 性能测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_count_train = count_vec.fit_transform(X_train) # X_count_train 中的count指的是CountVectorizer中的count\n",
    "X_count_test = count_vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_count=MultinomialNB()# mnb_count 中的count指的是CountVectorizer中的count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用朴素贝叶斯分类器，对CountVectorizer(without filtering stop words)后的训练样本进行参数学习\n",
    "mnb_count.fit(X_count_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of classifying 20newsgroups using Naive Bayes(CountVectorizer without filtering stop words) is: 0.8397707979626485\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy of classifying 20newsgroups using Naive Bayes(CountVectorizer without filtering stop words) is: \" \n",
    "      +str(mnb_count.score(X_count_test,y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mnb_count=mnb_count.predict(X_count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.86      0.86      0.86       201\n",
      "           comp.graphics       0.59      0.86      0.70       250\n",
      " comp.os.ms-windows.misc       0.89      0.10      0.17       248\n",
      "comp.sys.ibm.pc.hardware       0.60      0.88      0.72       240\n",
      "   comp.sys.mac.hardware       0.93      0.78      0.85       242\n",
      "          comp.windows.x       0.82      0.84      0.83       263\n",
      "            misc.forsale       0.91      0.70      0.79       257\n",
      "               rec.autos       0.89      0.89      0.89       238\n",
      "         rec.motorcycles       0.98      0.92      0.95       276\n",
      "      rec.sport.baseball       0.98      0.91      0.95       251\n",
      "        rec.sport.hockey       0.93      0.99      0.96       233\n",
      "               sci.crypt       0.86      0.98      0.91       238\n",
      "         sci.electronics       0.85      0.88      0.86       249\n",
      "                 sci.med       0.92      0.94      0.93       245\n",
      "               sci.space       0.89      0.96      0.92       221\n",
      "  soc.religion.christian       0.78      0.96      0.86       232\n",
      "      talk.politics.guns       0.88      0.96      0.92       251\n",
      "   talk.politics.mideast       0.90      0.98      0.94       231\n",
      "      talk.politics.misc       0.79      0.89      0.84       188\n",
      "      talk.religion.misc       0.93      0.44      0.60       158\n",
      "\n",
      "             avg / total       0.86      0.84      0.82      4712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true=y_test,y_pred=y_pred_mnb_count,target_names=news.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用TfidfVectorizer (Term Frequency Inverse Document Frequency)并且不去除停用词的条件下，对文本特征进行量化的naive bayes classifier 的性能分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf_train=tfidf_vec.fit_transform(X_train)\n",
    "X_tfidf_test=tfidf_vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_tfidf=MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_tfidf.fit(X_tfidf_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mnb_tfidf=mnb_tfidf.predict(X_tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of classifying 20newsgroups with Naive Bayes (TfidfVectorizer without filtering stop words) is : 0.8463497453310697\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy of classifying 20newsgroups with Naive Bayes (TfidfVectorizer without filtering stop words) is : \"\n",
    "     +str(mnb_tfidf.score(X=X_tfidf_test,y=y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.67      0.75       201\n",
      "          1       0.85      0.74      0.79       250\n",
      "          2       0.82      0.85      0.83       248\n",
      "          3       0.76      0.88      0.82       240\n",
      "          4       0.94      0.84      0.89       242\n",
      "          5       0.96      0.84      0.89       263\n",
      "          6       0.93      0.69      0.79       257\n",
      "          7       0.84      0.92      0.88       238\n",
      "          8       0.98      0.92      0.95       276\n",
      "          9       0.96      0.91      0.94       251\n",
      "         10       0.88      0.99      0.93       233\n",
      "         11       0.73      0.98      0.83       238\n",
      "         12       0.91      0.83      0.87       249\n",
      "         13       0.97      0.92      0.95       245\n",
      "         14       0.89      0.96      0.93       221\n",
      "         15       0.51      0.97      0.67       232\n",
      "         16       0.83      0.96      0.89       251\n",
      "         17       0.92      0.97      0.95       231\n",
      "         18       0.98      0.62      0.76       188\n",
      "         19       0.93      0.16      0.28       158\n",
      "\n",
      "avg / total       0.87      0.85      0.84      4712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test,y_pred=y_pred_mnb_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分别使用CountVectorizer 和 TfidfVectorizer（with filtering stop words），对文本特征进行量化的Naive Bayes Classifier 进行performance test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_filter_vec=CountVectorizer(analyzer='word',stop_words='english')\n",
    "tfidf_filter_vec=TfidfVectorizer(analyzer='word',stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用带有stopwords停用词filter的CountVectorizer对train和test分别进行量化处理\n",
    "X_count_filter_train=count_filter_vec.fit_transform(X_train)\n",
    "X_count_filter_test=count_filter_vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用带有停用词filter的TfidfVectorizer(term frequency inverse document frequency)对train和test分别进行量化处理\n",
    "X_tfidf_filter_train=tfidf_filter_vec.fit_transform(X_train)\n",
    "X_tfidf_filter_test=tfidf_filter_vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of classifying 20newsgroups using Naive Bayes(CountVectorizer by filtering stopwords)0.8637521222410866\n"
     ]
    }
   ],
   "source": [
    "# 初始化默认配置的朴素贝叶斯分类器，并对CountVectorizer后的数据进行predict和accuracy分析\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb_count_filter=MultinomialNB()\n",
    "mnb_count_filter.fit(X_count_filter_train,y_train)\n",
    "print(\"The accuracy of classifying 20newsgroups using Naive Bayes(CountVectorizer by filtering stopwords)\"\n",
    "     +str(mnb_count_filter.score(X_count_filter_test,y_test)))\n",
    "\n",
    "y_pred_mnb_count_filter=mnb_count_filter.predict(X_count_filter_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of classifying 20newsgroup using Naive Bayes(TfidfVectorizer by filtering stopwords)0.8826400679117148\n"
     ]
    }
   ],
   "source": [
    "# 初始化另一个默认配置的朴素贝叶斯分类器，并对TfidfVectorizer后的数据进行predict和accuracy分析\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb_tfidf_filter=MultinomialNB()\n",
    "mnb_tfidf_filter.fit(X_tfidf_filter_train,y_train)\n",
    "print(\"The accuracy of classifying 20newsgroup using Naive Bayes(TfidfVectorizer by filtering stopwords)\"\n",
    "     +str(mnb_tfidf_filter.score(X_tfidf_filter_test,y_test)))\n",
    "\n",
    "y_pred_mnb_tfidf_filter=mnb_tfidf_filter.predict(X=X_tfidf_filter_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.89      0.87       201\n",
      "          1       0.62      0.88      0.73       250\n",
      "          2       0.93      0.22      0.36       248\n",
      "          3       0.62      0.88      0.73       240\n",
      "          4       0.93      0.85      0.89       242\n",
      "          5       0.82      0.85      0.84       263\n",
      "          6       0.90      0.79      0.84       257\n",
      "          7       0.91      0.91      0.91       238\n",
      "          8       0.98      0.94      0.96       276\n",
      "          9       0.98      0.92      0.95       251\n",
      "         10       0.92      0.99      0.95       233\n",
      "         11       0.91      0.97      0.93       238\n",
      "         12       0.87      0.89      0.88       249\n",
      "         13       0.94      0.95      0.95       245\n",
      "         14       0.91      0.96      0.93       221\n",
      "         15       0.87      0.94      0.90       232\n",
      "         16       0.89      0.96      0.93       251\n",
      "         17       0.95      0.98      0.97       231\n",
      "         18       0.84      0.90      0.87       188\n",
      "         19       0.91      0.53      0.67       158\n",
      "\n",
      "avg / total       0.88      0.86      0.85      4712\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.81      0.83       201\n",
      "          1       0.85      0.81      0.83       250\n",
      "          2       0.84      0.87      0.86       248\n",
      "          3       0.78      0.88      0.83       240\n",
      "          4       0.92      0.90      0.91       242\n",
      "          5       0.95      0.88      0.91       263\n",
      "          6       0.90      0.80      0.85       257\n",
      "          7       0.89      0.92      0.90       238\n",
      "          8       0.98      0.94      0.96       276\n",
      "          9       0.97      0.93      0.95       251\n",
      "         10       0.88      0.99      0.93       233\n",
      "         11       0.85      0.98      0.91       238\n",
      "         12       0.93      0.86      0.89       249\n",
      "         13       0.96      0.93      0.95       245\n",
      "         14       0.90      0.97      0.93       221\n",
      "         15       0.70      0.96      0.81       232\n",
      "         16       0.84      0.98      0.90       251\n",
      "         17       0.92      0.99      0.95       231\n",
      "         18       0.97      0.74      0.84       188\n",
      "         19       0.96      0.29      0.45       158\n",
      "\n",
      "avg / total       0.89      0.88      0.88      4712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 对以上两个模型进行更加详细的性能评估\n",
    "from sklearn.metrics import classification_report\n",
    "# CountVectorizer模型性能评估\n",
    "print(classification_report(y_true=y_test,y_pred=y_pred_mnb_count_filter))\n",
    "# TfidfVectorizer模型性能评估\n",
    "print(classification_report(y_true=y_test,y_pred=y_pred_mnb_tfidf_filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
