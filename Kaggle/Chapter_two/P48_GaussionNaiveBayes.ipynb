{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "news=fetch_20newsgroups(subset='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data size is :18846\n",
      "The detail of data[0] is :From: Mamatha Devineni Ratnam <mr47+@andrew.cmu.edu>\n",
      "Subject: Pens fans reactions\n",
      "Organization: Post Office, Carnegie Mellon, Pittsburgh, PA\n",
      "Lines: 12\n",
      "NNTP-Posting-Host: po4.andrew.cmu.edu\n",
      "\n",
      "\n",
      "\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
      "to non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\n",
      "are killing those Devils worse than I thought. Jagr just showed you why\n",
      "he is much better than his regular season stats. He is also a lot\n",
      "fo fun to watch in the playoffs. Bowman should let JAgr have a lot of\n",
      "fun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\n",
      "regular season game.          PENS RULE!!!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('The data size is :'+str(len(news.data))) # 检查数据规模\n",
    "print('The detail of data[0] is :'+str(news.data[0])) # 检查数据细节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(news.data,news.target,test_size=0.25,random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer() # 这句话是必须的，vec再下面fit过程中能拿到数据mean和variance的信息\n",
    "X_train= vec.fit_transform(X_train)\n",
    "X_test = vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB #如果如果样本特征的分大部分是多元离散值，使用MultinomialNB比较合适"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_y_predict = mnb.predict(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of MultinomialNaiveBayes Classifier is :0.8397707979626485\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy of MultinomialNaiveBayes Classifier is :\" +str(mnb.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86       201\n",
      "           1       0.59      0.86      0.70       250\n",
      "           2       0.89      0.10      0.17       248\n",
      "           3       0.60      0.88      0.72       240\n",
      "           4       0.93      0.78      0.85       242\n",
      "           5       0.82      0.84      0.83       263\n",
      "           6       0.91      0.70      0.79       257\n",
      "           7       0.89      0.89      0.89       238\n",
      "           8       0.98      0.92      0.95       276\n",
      "           9       0.98      0.91      0.95       251\n",
      "          10       0.93      0.99      0.96       233\n",
      "          11       0.86      0.98      0.91       238\n",
      "          12       0.85      0.88      0.86       249\n",
      "          13       0.92      0.94      0.93       245\n",
      "          14       0.89      0.96      0.92       221\n",
      "          15       0.78      0.96      0.86       232\n",
      "          16       0.88      0.96      0.92       251\n",
      "          17       0.90      0.98      0.94       231\n",
      "          18       0.79      0.89      0.84       188\n",
      "          19       0.93      0.44      0.60       158\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      4712\n",
      "   macro avg       0.86      0.84      0.82      4712\n",
      "weighted avg       0.86      0.84      0.82      4712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test,y_pred=mnb_y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 朴素贝叶斯模型被广泛应用于海量互联网文本分类任务，由于其较强的特征条件独立假设，使得模型预测所需要的估计的参数规模从幂数量级，向线性数量级减少，极大的节约了内从消耗和计算时间。\n",
    "* 但是，也正是受到这种强假设的约束，模型训练时无法将各个特征之间的联系考量在内，使得该模型在其他数据特征（关联性较强的）分类任务上的性能表现不佳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
